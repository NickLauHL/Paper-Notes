---
title: "ResNet 深度残差学习网络"
date: 2024-01-20
categories: [计算机视觉]
tags: [CNN, 残差学习, 图像分类]
paper_info:
  authors: "He et al."
  venue: "CVPR 2016"
  year: 2016
  link: "https://arxiv.org/abs/1512.03385"
---

这篇论文提出了残差学习框架，解决了深度网络训练中的退化问题。

## 问题背景

随着网络深度增加，训练误差反而上升。这不是过拟合问题，而是优化困难导致的退化问题。

## 核心思想

引入"残差连接"（skip connection）：

```
y = F(x) + x
```

网络不再直接学习底层映射 H(x)，而是学习残差映射 F(x) = H(x) - x。

## 网络结构

### 残差块设计

两种基本残差块：

| 类型 | 层数 | 适用场景 |
|------|------|----------|
| BasicBlock | 2层 | ResNet-18/34 |
| Bottleneck | 3层 | ResNet-50/101/152 |

### 整体架构

- 初始卷积层：7×7, stride 2
- 4个残差阶段
- 全局平均池化
- 全连接分类层

## 实验结果

- ImageNet 分类错误率：3.57%（集成模型）
- COCO 检测 mAP 提升显著
- 赢得 ILSVRC 2015 分类任务冠军

## 关键洞见

1. 残差连接使得梯度可以直接反向传播到浅层
2. 恒等映射比零映射更容易学习
3. 网络深度可以达到上千层（ResNet-1001）

## 延伸阅读

- DenseNet：密集连接
- ResNeXt：分组卷积版本
- SENet：通道注意力增强
